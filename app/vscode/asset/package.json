{
  "publisher": "Privy",
  "name": "privy-vscode",
  "version": "0.2.8",
  "displayName": "Privy - AI coding Autocomplete and chat that runs locally. ",
  "description": "Get code suggestions, chat with code, explain code, generate tests, find bugs, etc.",
  "keywords": [
    "ai",
    "autocomplete",
    "code completion",
    "llama.cpp",
    "ollama",
    "mistral",
    "chatgpt",
    "gpt",
    "openai",
    "codex",
    "copilot",
    "code explanation"
  ],
  "categories": [
    "Machine Learning",
    "Programming Languages",
    "Linters",
    "Formatters",
    "Data Science",
    "Education",
    "Testing",
    "Snippets"
  ],
  "icon": "media/extension-icon.png",
  "galleryBanner": {
    "color": "#000000",
    "theme": "dark"
  },
  "license": "SEE LICENSE IN LICENSE.txt",
  "engines": {
    "node": ">=18",
    "vscode": "^1.72.0"
  },
  "homepage": "https://github.com/srikanth235/privy",
  "repository": "https://github.com/srikanth235/privy",
  "bugs": "https://github.com/srikanth235/privy/issues",
  "extensionKind": [
    "workspace"
  ],
  "main": "./extension/dist/extension.js",
  "activationEvents": [
    "onStartupFinished"
  ],
  "contributes": {
    "commands": [
      {
        "command": "privy.startChat",
        "title": "Start Chat ðŸ’¬",
        "category": "Privy",
        "icon": "$(comment-discussion)"
      },
      {
        "command": "privy.explainCode",
        "title": "Explain Code",
        "category": "Privy",
        "icon": "$(comment-discussion)"
      },
      {
        "command": "privy.generateCode",
        "title": "Generate Code ðŸª„",
        "category": "Privy",
        "icon": "$(wand)"
      },
      {
        "command": "privy.generateUnitTest",
        "title": "Generate Unit Test ðŸª„",
        "category": "Privy",
        "icon": "$(beaker)"
      },
      {
        "command": "privy.diagnoseErrors",
        "title": "Diagnose Errors",
        "category": "Privy",
        "icon": "$(search-fuzzy)"
      },
      {
        "command": "privy.findBugs",
        "title": "Find Bugs",
        "category": "Privy",
        "icon": "$(bug)"
      },
      {
        "command": "privy.touchBar.startChat",
        "category": "Privy",
        "title": "ðŸ’¬"
      },
      {
        "command": "privy.showChatPanel",
        "title": "Show Chat Panel ðŸ’¬",
        "category": "Privy",
        "icon": "$(comment-discussion)"
      },
      {
        "command": "privy.getStarted",
        "title": "Get Started",
        "category": "Privy",
        "icon": "$(question)"
      },
      {
        "command": "privy.openSettings",
        "title": "Open Settings",
        "category": "Privy",
        "icon": "$(settings)"
      },
      {
        "command": "privy.reloadTemplates",
        "title": "Reload Templates",
        "category": "Privy",
        "icon": "$(sync)"
      },
      {
        "command": "privy.showLogs",
        "title": "Show Logs",
        "category": "Privy",
        "icon": "$(output)"
      }
    ],
    "configuration": {
      "title": "Privy",
      "properties": {
        "privy.logger.level": {
          "type": "string",
          "default": "info",
          "enum": [
            "debug",
            "info",
            "warning",
            "error"
          ],
          "enumDescriptions": [
            "Show all logs",
            "Show all logs except the debug ones",
            "Only show warnings and errors",
            "Only show errors"
          ],
          "markdownDescription": "Specify the verbosity of logs that will appear in 'Privy: Show Logs'.",
          "scope": "application",
          "order": 1
        },
        "privy.provider": {
          "type": "string",
          "default": "Ollama",
          "enum": [
            "Ollama",
            "llamafile",
            "llama.cpp"
          ],
          "enumDescriptions": [
            "One of the fastest ways to get started with local models on Mac/Linux",
            "If you are running LLM with this self-contained binary",
            "If you are running llama.cpp server from source"
          ],
          "order": 2
        },
        "privy.providerBaseUrl": {
          "type": "string",
          "default": "http://localhost:11434/",
          "markdownDescription": "Specify the URL to the provider.",
          "scope": "application",
          "order": 3
        },
        "privy.autocomplete.mode": {
          "type": "string",
          "default": "automatic",
          "enum": [
            "automatic",
            "manual",
            "disabled"
          ],
          "enumDescriptions": [
            "If you prefer to use the autocomplete functionality automatically. ",
            "If you prefer to trigger manually. (Cmd + \\ for macs & Alt + \\ for others)",
            "If you don't want to use autocomplete functionality."
          ],
          "order": 4
        },
        "privy.autocomplete.model": {
          "type": "string",
          "default": "deepseek-coder:1.3b-base",
          "markdownDescription": "Enter the name of Ollama model to use for autocomplete.",
          "order": 5
        },
        "privy.autocomplete.debounceWait": {
          "type": "number",
          "default": 300,
          "markdownDescription": "The time gap before triggering the next completion in milliseconds",
          "order": 6
        },
        "privy.model": {
          "type": "string",
          "default": "mistral:instruct",
          "enum": [
            "mistral:instruct",
            "codellama:instruct",
            "custom"
          ],
          "enumDescriptions": [
            "A 7b parameter base model created by Mistral AI, very competent for code generation and other tasks. ",
            "A model from Meta, fine-tuned for code generation and conversation",
            "For Ollama, use this for custom models that are not listed above."
          ],
          "markdownDescription": "Select the AI model that you want to chat with.",
          "scope": "application",
          "order": 7
        },
        "privy.customModel": {
          "type": "string",
          "default": "",
          "markdownDescription": "Enter the name of Ollama model to use. Only applies if you selected 'custom' above.",
          "order": 8
        },
        "privy.syntaxHighlighting.useVisualStudioCodeColors": {
          "type": "boolean",
          "default": false,
          "markdownDescription": "Use the Visual Studio Code Theme colors for syntax highlighting in the diff viewer. Might not work with all themes. Only applies to newly opened diffs.",
          "scope": "application",
          "order": 9
        },
        "privy.indexRepository.enabled": {
          "type": "boolean",
          "default": false,
          "markdownDescription": "Enable the command to index your repository and give more context to the AI model. Experimental.",
          "scope": "application",
          "order": 10
        }
      }
    },
    "keybindings": [
      {
        "key": "cmd+\\",
        "command": "editor.action.inlineSuggest.trigger",
        "when": "config.privy.autocomplete.mode === 'manual' && editorTextFocus && !editorHasSelection && !inlineSuggestionsVisible && isMac"
      },
      {
        "key": "alt+\\",
        "command": "editor.action.inlineSuggest.trigger",
        "when": "config.privy.autocomplete.mode === 'manual' && editorTextFocus && !editorHasSelection && !inlineSuggestionsVisible && !isMac"
      },
      {
        "command": "privy.startChat",
        "when": "isMac",
        "key": "Ctrl+Cmd+c"
      },
      {
        "command": "privy.startChat",
        "when": "!isMac",
        "key": "Ctrl+Alt+c"
      },
      {
        "command": "privy.generateCode",
        "when": "isMac",
        "key": "Ctrl+Cmd+g"
      },
      {
        "command": "privy.generateCode",
        "when": "!isMac",
        "key": "Ctrl+Alt+g"
      }
    ],
    "submenus": [
      {
        "label": "Privy",
        "id": "privy.submenu"
      }
    ],
    "menus": {
      "view/title": [
        {
          "command": "privy.startChat",
          "when": "view == privy.chat",
          "group": "navigation@1"
        },
        {
          "command": "privy.openSettings",
          "when": "view == privy.chat",
          "group": "navigation@2"
        },
        {
          "command": "privy.getStarted",
          "when": "view == privy.chat",
          "group": "navigation@3"
        }
      ],
      "touchBar": [
        {
          "command": "privy.touchBar.startChat",
          "group": "privy"
        }
      ],
      "commandPalette": [
        {
          "command": "privy.touchBar.startChat",
          "when": "false"
        }
      ],
      "editor/context": [
        {
          "submenu": "privy.submenu",
          "group": "0_privy"
        }
      ],
      "privy.submenu": [
        {
          "command": "privy.startChat",
          "group": "privy"
        },
        {
          "command": "privy.explainCode",
          "group": "privy"
        },
        {
          "command": "privy.findBugs",
          "group": "privy"
        },
        {
          "command": "privy.generateUnitTest",
          "group": "privy"
        },
        {
          "command": "privy.diagnoseErrors",
          "group": "privy"
        }
      ]
    },
    "viewsContainers": {
      "activitybar": [
        {
          "id": "privy",
          "title": "Privy",
          "icon": "media/sidebar-icon.svg"
        }
      ]
    },
    "views": {
      "privy": [
        {
          "id": "privy.chat",
          "name": "Chat",
          "type": "webview"
        }
      ]
    },
    "walkthroughs": [
      {
        "id": "privy",
        "title": "Privy",
        "description": "Your AI Chat Assistant in Visual Studio Code",
        "steps": [
          {
            "id": "setup",
            "title": "Setup Privy",
            "description": "Ensure LLM is running locally before getting started.",
            "media": {
              "markdown": "walkthrough/setup.md"
            }
          },
          {
            "id": "autocomplete",
            "title": "Autocomplete",
            "description": "Get suggestions from your LLM as and when you type.",
            "media": {
              "markdown": "walkthrough/autocomplete.md"
            }
          },
          {
            "id": "chat",
            "title": "AI Chat",
            "description": "Chat with Privy about your code and software development topics.",
            "media": {
              "markdown": "walkthrough/chat.md"
            }
          },
          {
            "id": "explain-code",
            "title": "Explain Code",
            "description": "Chat with Privy about your code and software development topics.",
            "media": {
              "markdown": "walkthrough/explain-code.md"
            }
          },
          {
            "id": "generate-unit-test",
            "title": "Generate Unit Test",
            "description": "Chat with Privy about your code and software development topics.",
            "media": {
              "markdown": "walkthrough/generate-unit-test.md"
            }
          },
          {
            "id": "find-bugs",
            "title": "Find Bugs",
            "description": "Chat with Privy about your code and software development topics.",
            "media": {
              "markdown": "walkthrough/find-bugs.md"
            }
          },
          {
            "id": "diagnose-errors",
            "title": "Diagnose Errors",
            "description": "Chat with Privy about your code and software development topics.",
            "media": {
              "markdown": "walkthrough/diagnose-errors.md"
            }
          },
          {
            "id": "tips-and-tricks",
            "title": "Tips and Tricks",
            "description": "How to get the most out of Privy.",
            "media": {
              "markdown": "walkthrough/tips-and-tricks.md"
            }
          },
          {
            "id": "project",
            "title": "Project",
            "description": "Learn more about our open source project.",
            "media": {
              "markdown": "walkthrough/project.md"
            }
          }
        ]
      }
    ]
  }
}
